â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                  â•‘
â•‘              ğŸš€ LM STUDIO - QUICK REFERENCE CARD ğŸš€              â•‘
â•‘                     For VEDA AI Users                            â•‘
â•‘                                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¥ INSTALLATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Download: https://lmstudio.ai/
2. Install: Run installer
3. Launch: Open from Start Menu

ğŸ¤– RECOMMENDED MODELS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Low-End PC (4GB RAM):
  â€¢ Phi-3 Mini Q4_K_M (~2GB) â­â­â­â­â­

Mid-Range PC (8GB RAM):
  â€¢ Llama 3.2 3B Q4_K_M (~2GB) â­â­â­â­
  â€¢ Mistral 7B Q4_K_M (~4GB) â­â­â­â­â­

High-End PC (16GB+ RAM):
  â€¢ Llama 3.1 8B Q5_K_M (~6GB) â­â­â­â­â­
  â€¢ Mistral 7B Q8_0 (~8GB) â­â­â­â­â­

ğŸ“¥ DOWNLOAD MODEL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Click "Discover" tab
2. Search: "Phi-3" (or your choice)
3. Select model
4. Choose: GGUF format
5. Pick: Q4_K_M quantization
6. Click "Download"
7. Wait for completion

ğŸ”Œ START SERVER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Go to "Local Server" tab
2. Click "Select a model to load"
3. Choose downloaded model
4. Click "Load Model"
5. Wait for "Model loaded"
6. Click "Start Server"
7. Verify: âœ… Server running on port 1234

âš™ï¸ VEDA AI CONFIGURATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Your .env file (already configured):

AI_MODE=self_training
LM_STUDIO_MODEL=local-model
LM_STUDIO_API_URL=http://localhost:1234
LM_STUDIO_TIMEOUT=60
LM_STUDIO_MAX_RETRIES=2

No changes needed!

ğŸš€ START VEDA AI
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Method 1 (Best):
  start_veda_fixed.bat

Method 2:
  python run_veda_ai.py

ğŸ§ª TESTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Test 1 - Check LM Studio:
  Browser: http://localhost:1234/v1/models
  Should show: JSON with model info

Test 2 - Test VEDA AI:
  Command: "Hello VEDA"
  Check logs: "Using LM Studio model: local-model"

ğŸ› TROUBLESHOOTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Problem: "LM Studio not running"
Solution:
  1. Open LM Studio
  2. Load model
  3. Start server
  4. Check green indicator

Problem: "Connection refused"
Solution:
  1. Verify server running
  2. Check port 1234 not blocked
  3. Check firewall

Problem: "Slow responses"
Solution:
  1. Use Phi-3 Mini
  2. Use Q4_K_M quantization
  3. Close other apps
  4. Increase timeout in .env

Problem: "Out of memory"
Solution:
  1. Use smaller model
  2. Close other apps
  3. Restart computer
  4. Use Q4_K_M quantization

ğŸ’¡ PRO TIPS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â€¢ Keep LM Studio server running in background
â€¢ Use Phi-3 Mini for speed, Mistral for quality
â€¢ Q4_K_M is best balance of speed/quality
â€¢ Enable GPU acceleration in LM Studio settings
â€¢ Monitor RAM usage in Task Manager
â€¢ Keep 2-3 models downloaded for flexibility

ğŸ“š DOCUMENTATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

English Guide:
  LM_STUDIO_SETUP.md

Hindi Guide:
  LM_STUDIO_SETUP_HINDI.md

Migration Guide:
  OLLAMA_TO_LM_STUDIO_MIGRATION.md

Complete Summary:
  OLLAMA_REPLACED_WITH_LM_STUDIO.md

ğŸ¯ QUICK START CHECKLIST
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â–¡ Install LM Studio
â–¡ Download Phi-3 Mini model
â–¡ Load model in "Local Server"
â–¡ Start server (port 1234)
â–¡ Verify at http://localhost:1234/v1/models
â–¡ Run start_veda_fixed.bat
â–¡ Test with "Hello VEDA"
â–¡ Check logs for "Using LM Studio model"

ğŸ”— USEFUL LINKS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

LM Studio:
  https://lmstudio.ai/

Discord:
  https://discord.gg/lmstudio

Models:
  https://huggingface.co/models?library=gguf

VEDA AI Docs:
  See DOCUMENTATION.md

âœ… BENEFITS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Easy GUI interface (no CLI needed)
âœ… Visual model management
âœ… OpenAI-compatible API
âœ… Better Windows support
âœ… Real-time monitoring
âœ… Built-in model browser
âœ… 100% privacy (fully local)
âœ… No API costs (completely free)
âœ… Offline mode (no internet needed)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Version: 1.0
Date: January 2026
Status: âœ… Production Ready
Tested: Windows 10/11

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ™ ENJOY VEDA AI WITH LM STUDIO! ğŸš€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
